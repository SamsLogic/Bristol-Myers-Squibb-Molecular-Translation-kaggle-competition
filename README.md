# Bristol-Myers-Squibb-Molecular-Translation-kaggle-competition
Link to the competition - https://www.kaggle.com/c/bms-molecular-translation/overview

## Background of the competiton

Bristol-Myers Squibb is a global biopharmaceutical company working to transform patients' lives through science. Their mission is to discover, develop, and deliver innovative medicines that help patients prevail over serious diseases.

In this competition, youâ€™ll interpret old chemical images. With access to a large set of synthetic image data generated by Bristol-Myers Squibb, you'll convert images back to the underlying chemical structure annotated as InChI text.

## Data

In this competition, you are provided with images of chemicals, with the objective of predicting the corresponding International Chemical Identifier (InChI) text string of the image. The images provided (both in the training data as well as the test data) may be rotated to different angles, be at various resolutions, and have different noise levels.

## Training

## My Approach

My approach to solve the problem was to progressively build my model. I started with learning about InChI Notations and the various layers in the InChI notation. After gaining fair understanding of the notation i started scripting with the code. My first major problem was tokenization of data and data preprocessing to input into any tensorflow model. 

## Text data

 This notatoin **InChI=1S/C2H6O/c1-2-3/h3H,2H2,1H3** contains just 1 layer of InChI that includes the main chemcial formula, carbon bonds and then hydrogen bonds. Now in order to tokenize the data i had three options -  character level tokenization , word level tokenization (delimitor = "/") and custom tokenization(Hybrid Tokenization).
 
 ### Character Level Tokenization
 
 This method would tokeinze the whole InChI notation and treat every character as a token. This method had multple issue and the major one was character level tokenization of numbers using this method it trated every number as a token this method would heavily impact the training as it would make it very difficult for the model to identify pattern as it will take numbers like "60" as "6" and "0" which would affect the ediction to a lot much extent. This method is useful in case where the posibilty of numbers are endless but this use case is redundant which i will show in further tokenizations.
 
 ### Word Level Tokenization
 
 Word Level tokenization is tokenizing the sequence or string with every word as a token where a word can be defrentiated with a delimiter. In this case the most probable delimiter would be "/" which in turn divide the sequence like this - {"nChI=1S":0, "C2H6O":1, "c1-2-3":2, "h3H,2H2,1H3":3}. This type of tokenization would be worst of three as there would be no understanding of the string and model won't be able to find clear patterns.
 
 ### Custom or Hybrid Tokenization
 
 By creating my own custom tokens specific to the sequence i divied the sequences using a hybrid of character and word level tokenization. Where every alphabet is considered as a token (Exceptions were in cases like Br, Si,etc) but every number should be taken as the number itself instead of every unit of a number as an individual. 
 
After tokenization was finalized the next problem was preprcoessing the tokens for the model.
Post tokenization, labels were required to be maintained as per the loss function for the model. In the baseline model, loss function used was sigmoid loss for which the data was needed to be converted into one hot encodings but the followup models this loss function was dropped and sparse ctegorical crossentropy was used to calculate loss.

## Image Data

The image dataset included grayscale images of inorganic compounds' structural formula. Foreg:
![image](https://user-images.githubusercontent.com/41964069/150637780-b7afe03b-12e3-4a3f-807e-10c5101e0ee0.png)

As seen above, these images included a very little amount of relevant data that can be understood by the machine or rather the images were highly sparse with only little amount of data. 

## Model

My first and foremost thought was to use a ConvRNN as my baseline model for which only minimal preprocessing was required beacuse the image data can be directly fed to the model for training. Then coming up with other model architectures it was realized that only minimal preprocessing of image data was requried. At last, Transformer model with Bahadanu's Attention based approach was used to solve the problem as the task was to transform image data to text data.

## Libraries Used

1. Numpy
2. Tensorflow
3. Keras
4. OpenCV
5. Matplotlib
6. Sklearn



